{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prise en mains de igraph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import os\n",
    "# # !find /usr/local -name \"pyspark\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/djeghali/spark\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session started, its id is  local-1707047423644\n"
     ]
    }
   ],
   "source": [
    "# Main imports\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# for dataframe and udf\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# initialise environment variables for spark\n",
    "findspark.init()\n",
    "\n",
    "# Start spark session\n",
    "# --------------------------\n",
    "def start_spark():\n",
    "  local = \"local[*]\"\n",
    "  appName = \"TP\"\n",
    "\n",
    "  gf = \"graphframes:graphframes:0.8.3-spark3.5-s_2.12\"\n",
    "\n",
    "  configLocale = SparkConf().setAppName(appName).setMaster(local).\\\n",
    "  set(\"spark.executor.memory\", \"6G\").\\\n",
    "  set(\"spark.driver.memory\",\"6G\").\\\n",
    "  set(\"spark.sql.catalogImplementation\",\"in-memory\").\\\n",
    "  set(\"spark.jars.packages\", gf)\n",
    "\n",
    "  spark = SparkSession.builder.config(conf = configLocale).getOrCreate()\n",
    "  sc = spark.sparkContext\n",
    "  sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "  spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\",\"-1\")\n",
    "\n",
    "  # Adjust the query execution environment to the size of the cluster (4 cores)\n",
    "  spark.conf.set(\"spark.sql.shuffle.partitions\",\"4\")\n",
    "  print(\"session started, its id is \", sc.applicationId)\n",
    "  return spark\n",
    "spark = start_spark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import GraphFrames\n",
    "from graphframes import GraphFrame\n",
    "from graphframes.lib import AggregateMessages as AM\n",
    "# from graphframes.lib import Pregel\n",
    "\n",
    "#For connectedComponents()\n",
    "# !pwd\n",
    "# !mkdir -p /content/checkpoints\n",
    "# spark.sparkContext.setCheckpointDir('/content/checkpoints')\n",
    "\n",
    "#Import networkx\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# Initialisez une session Spark\n",
    "spark = SparkSession.builder.appName(\"LectureParquet\").getOrCreate()\n",
    "# Chemin vers le fichier Parquet compressé avec Snappy\n",
    "parquet_file_10K = \"local/data/BDLE_10K/*.snappy.parquet\"\n",
    "parquet_file_1M = \"local/data/BDLE_1M/*.snappy.parquet\"\n",
    "\n",
    "# Lisez le fichier Parquet dans un DataFrame PySpark\n",
    "data_10K = spark.read.format(\"parquet\").option(\"compression\", \"snappy\").load(parquet_file_10K)\n",
    "data_1M = spark.read.format(\"parquet\").option(\"compression\", \"snappy\").load(parquet_file_1M)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+\n",
      "|     seqID1|     seqID2|  sim|\n",
      "+-----------+-----------+-----+\n",
      "|117761605:5|152890023:5| 97.8|\n",
      "|152904885:3|155591878:2| 88.5|\n",
      "|152887848:4|153682181:0|100.0|\n",
      "|152937692:5| 80009514:2| 82.3|\n",
      "|152990923:2|154549183:4| 98.0|\n",
      "|152867782:1|153171917:1| 83.1|\n",
      "| 15111981:2|153137370:1|100.0|\n",
      "|152794195:0| 15280704:2| 96.9|\n",
      "| 62963742:1| 63783418:5| 98.4|\n",
      "|152170568:3|153062631:2| 97.6|\n",
      "|152904832:4|154500443:5| 98.6|\n",
      "|152745429:3| 22988511:2|100.0|\n",
      "|153161980:3|154256473:0|100.0|\n",
      "|152903373:4|154426964:5| 80.4|\n",
      "|146010871:1|158434400:4| 98.7|\n",
      "|153040013:0|156563807:1| 96.5|\n",
      "|152933621:4|157634534:2| 96.8|\n",
      "|153141720:0|155282497:0| 93.2|\n",
      "|153082115:5|153887336:3| 90.0|\n",
      "|153025447:3|155660759:1| 97.4|\n",
      "+-----------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Nombre de tuples dans les données de taille 10K  :  20842\n"
     ]
    }
   ],
   "source": [
    "# Affichez le contenu du DataFrame\n",
    "data_10K.show()\n",
    "print(\"Nombre de tuples dans les données de taille 10K  : \",data_10K.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|              seqID1|              seqID2|  sim|\n",
      "+--------------------+--------------------+-----+\n",
      "|          28266027:2|          30697475:4|100.0|\n",
      "|         141099253:1|         142374057:2| 87.8|\n",
      "|         100479579:0|          23509310:0| 83.9|\n",
      "|         113579361:3|         114583521:5|100.0|\n",
      "|         127898390:3|         142186630:2|100.0|\n",
      "|          19430332:0|          78781103:4| 85.4|\n",
      "|         141834541:2|         145255331:5|100.0|\n",
      "|         103259805:4|          58392840:4| 83.3|\n",
      "|         122611397:5|         143667719:3|100.0|\n",
      "|          23535857:4|           4695744:1| 95.8|\n",
      "|          41064011:0|          58827273:4|100.0|\n",
      "|         107823489:0|         107855124:4| 85.1|\n",
      "|METdb_00146-1-DN1...|METdb_00154-1-DN1...| 92.6|\n",
      "|         156037355:1|         157677656:3| 88.9|\n",
      "|          36873489:1|          89199423:1| 93.1|\n",
      "|         119223634:3|         119895769:4| 88.7|\n",
      "|         126499401:5|         140644518:1|100.0|\n",
      "|         102837135:1|          92635480:5| 92.7|\n",
      "|          86428924:0|          96248458:3| 87.0|\n",
      "|TARA_MED_95_MAG_0...|TARA_MED_95_MAG_0...|100.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Nombre de tuples dans les données de taille 1M :  1768595\n"
     ]
    }
   ],
   "source": [
    "# Affichez le contenu du DataFrame 1M\n",
    "data_1M.show()\n",
    "print(\"Nombre de tuples dans les données de taille 1M : \",data_1M.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On converti en dataframe pandas :\n",
    "data_10K = data_10K.toPandas()\n",
    "data_1M = data_1M.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Génération des igraphes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créarion d'un graphe  à partir des données lues :\n",
    "data_10K_ig_graph = ig.Graph.TupleList(data_10K[['seqID1', 'seqID2']].itertuples(index=False), directed=False)\n",
    "data_1M_ig_graph = ig.Graph.TupleList(data_1M[['seqID1', 'seqID2']].itertuples(index=False), directed=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Calcule du temps de calcule des composantes connexes : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -   Data 10 K : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution : 0.01446843147277832 secondes\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Calculer les composantes connexes\n",
    "components = data_10K_ig_graph.components()\n",
    "\n",
    "# Afficher les composantes connexes\n",
    "# print(\"Composantes connexes :\", components)\n",
    "\n",
    "# Afficher le temps d'exécution\n",
    "end_time = time()\n",
    "execution_time_10K = end_time - start_time\n",
    "\n",
    "print(\"Temps d'exécution :\", execution_time_10K, \"secondes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -   Data 1 M : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution : 0.5444376468658447 secondes\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Calculer les composantes connexes\n",
    "components = data_1M_ig_graph.components()\n",
    "\n",
    "# Afficher les composantes connexes\n",
    "# print(\"Composantes connexes :\", components)\n",
    "\n",
    "# Afficher le temps d'exécution\n",
    "end_time = time()\n",
    "execution_time_1M = end_time - start_time\n",
    "\n",
    "print(\"Temps d'exécution :\", execution_time_1M, \"secondes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifier le multiprocessing de igraphe :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution paralèlle : 0.9021463394165039 secondes\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from igraph import Graph\n",
    "\n",
    "def process_1():\n",
    "    # Code du premier programme\n",
    "    components = data_1M_ig_graph.components()\n",
    "\n",
    "def process_2():\n",
    "    # Code du deuxième programme\n",
    "    components = data_1M_ig_graph.components()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Calculer les composantes connexes\n",
    "    # Créer deux processus pour exécuter les deux programmes en parallèle\n",
    "    p1 = multiprocessing.Process(target=process_1)\n",
    "    p2 = multiprocessing.Process(target=process_2)\n",
    "\n",
    "    start_time = time()\n",
    "\n",
    "    # Démarrer les deux processus\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    # Attendre que les deux processus se terminent\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "    # Afficher le temps d'exécution\n",
    "    end_time = time()\n",
    "    execution_time_2proccessus = end_time - start_time\n",
    "\n",
    "    print(\"Temps d'exécution paralèlle :\", execution_time_2proccessus, \"secondes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps total de traitement : 13.76425576210022 secondes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def process_subgraph(subgraph):\n",
    "    # Effectuez ici le traitement sur le sous-graphe\n",
    "    # Par exemple, calculer une métrique spécifique\n",
    "    result = subgraph.components()\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Chargez votre graphe à partir de votre source de données\n",
    "    # graph = ...\n",
    "\n",
    "    # Divisez le graphe en sous-graphes (vous pouvez ajuster la logique en fonction de votre besoin)\n",
    "    subgraphs = [data_1M_ig_graph,data_1M_ig_graph]\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Utilisez multiprocessing pour paralléliser le traitement des sous-graphes\n",
    "    with Pool() as pool:\n",
    "        results = pool.map(process_subgraph, subgraphs)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Temps total de traitement : {total_time} secondes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
