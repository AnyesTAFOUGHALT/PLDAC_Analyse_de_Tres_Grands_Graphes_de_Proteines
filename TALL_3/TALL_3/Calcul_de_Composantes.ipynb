{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10283eb5-ec5c-4dc2-bbde-885379805c1e",
   "metadata": {},
   "source": [
    "# Importation des bibliothéques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837e4dfb-cf49-44ef-af25-3125612f9a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphframes in /root/anaconda3/lib/python3.9/site-packages (0.6)\n",
      "Requirement already satisfied: numpy in /root/anaconda3/lib/python3.9/site-packages (from graphframes) (1.20.3)\n",
      "Requirement already satisfied: nose in /root/anaconda3/lib/python3.9/site-packages (from graphframes) (1.3.7)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01245d71-94ca-4841-ae25-6b0af3b45819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /root/anaconda3/lib/python3.9/site-packages (15.0.2)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in /root/anaconda3/lib/python3.9/site-packages (from pyarrow) (1.20.3)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7188203b-9057-42b1-a04e-896600e3e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# for dataframe and udf\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from igraph import Graph\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import collect_set, min as min_, expr,array_min,max\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "from graphframes import GraphFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392e33b6-6365-49bd-a624-179fdbffda99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/bin/pyspark\n",
      "/root/anaconda3/pkgs/pyspark-3.1.2-pyhd3eb1b0_0/site-packages/pyspark/bin/pyspark\n",
      "/root/anaconda3/lib/python3.9/site-packages/pyspark/bin/pyspark\n"
     ]
    }
   ],
   "source": [
    "!find /root -name \"pyspark\" |grep bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6628c2cb-50c7-44f2-8b92-1f9120741bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/java\n"
     ]
    }
   ],
   "source": [
    "!which java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99609d71-fea1-401e-aafd-7798f8d0e508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"11.0.14\" 2022-01-18\n",
      "OpenJDK Runtime Environment (build 11.0.14+9-post-Debian-1deb10u1)\n",
      "OpenJDK 64-Bit Server VM (build 11.0.14+9-post-Debian-1deb10u1, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d917936-d955-4fa0-a62d-31044687818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SPARK_HOME\"] =  \"/root/anaconda3/lib/python3.9/site-packages/pyspark\" \n",
    "os.environ[\"JAVA_HOME\"] =\"/usr\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f1f2d-0b08-43aa-a8be-cec18f233e23",
   "metadata": {},
   "source": [
    "# Lancer Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8377879c-e2f7-463c-b4ee-9006369a596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "findspark.init() initialise les variables d'environnement pour spark\n"
     ]
    }
   ],
   "source": [
    "import findspark \n",
    "print(\"findspark.init() initialise les variables d'environnement pour spark\") \n",
    "findspark.init() \n",
    "\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark import SparkConf  \n",
    "\n",
    "# import pyspark functions\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "from pyspark.sql.types import StringType, IntegerType, LongType, FloatType, ArrayType,StructType,StructField, BooleanType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20161817-a87f-4b0b-8f8b-3b01a7a802fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle 15\n",
      "session démarrée, son id est  local-1712144199484\n"
     ]
    }
   ],
   "source": [
    "def demarrer_spark():\n",
    "    \n",
    "  # 60 cores \n",
    "  NB_CORES = 5\n",
    "  # NB_CORES = 64\n",
    "  local = f\"local[{NB_CORES}]\"\n",
    "  # local = \"local[*]\"\n",
    "    \n",
    "\n",
    "  # le parametre spark.local.dir indique le repertoire contenant les données temporaires ecrites sur disque lorsque le shufle ne tient pas en memoire\n",
    "  \n",
    "    \n",
    "  appName = \"PLDAC\"\n",
    "  configLocale = SparkConf().setAppName(appName).setMaster(local).\\\n",
    "  set(\"spark.executor.memory\", \"320G\").\\\n",
    "  set(\"spark.driver.memory\",\"320G\").\\\n",
    "  set(\"spark.sql.catalogImplementation\",\"in-memory\").\\\n",
    "  set(\"spark.driver.maxResultSize\", \"20G\").\\\n",
    "  set(\"spark.local.dir\", \"/data/bd/spark/tmp\").\\\n",
    "  set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "    \n",
    "\n",
    "# # to allow sharing in memory arow format between pandas and spark : speeds up the creation of a spark df from a pandas df\n",
    "# spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "\n",
    "  spark = SparkSession.builder.config(conf = configLocale).getOrCreate()\n",
    "  sc = spark.sparkContext\n",
    "  sc.setLogLevel(\"ERROR\")\n",
    "  \n",
    "  # spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\",\"-1\")\n",
    "    \n",
    "  # On ajuste l'environnement d'exécution des requêtes à la taille du cluster (NB_CORES coeurs)\n",
    "  shuffle_partitions = 3 * NB_CORES\n",
    "  print(\"shuffle\", shuffle_partitions)\n",
    "  spark.conf.set(\"spark.sql.shuffle.partitions\", str(shuffle_partitions))    \n",
    "\n",
    "  print(\"session démarrée, son id est \", sc.applicationId)\n",
    "  return spark\n",
    "\n",
    "spark = demarrer_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8832dab-710d-49cf-94a4-2d8067aff31d",
   "metadata": {},
   "source": [
    "# Calcul en parallèle des composantes connectées pour tous les fichiers de partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea562a4-bb6e-48a3-957c-347b215ee2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_partition_components(partition_folder):\n",
    "    def components(partition_file) :\n",
    "        df = pd.read_parquet(partition_file)\n",
    "        g = Graph.TupleList(df[['query_id', 'target_id']].itertuples(index=False), directed=False)\n",
    "        connected_components = g.connected_components()\n",
    "        node_ids=[]\n",
    "        for component in connected_components:\n",
    "            node_ids.append([g.vs[node_index]['name'] for node_index in component])\n",
    "        #on trie en fonction de la taille \n",
    "        composantes_triees = sorted(node_ids, key=len, reverse=True)\n",
    "        # Créer une liste de lignes pour chaque composante\n",
    "        rows = []\n",
    "        for i, component in enumerate(composantes_triees):\n",
    "            for seqid in component:\n",
    "                rows.append((seqid , i))\n",
    "        return rows\n",
    "\n",
    "    # Schéma du DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"file\", StringType(), False)\n",
    "    ])\n",
    "    \n",
    "    # Données à partir desquelles créer le DataFrame\n",
    "    #data = [(file,) for file in os.listdir(partition_folder)]\n",
    "    data = [(i,) for i, file in enumerate(os.listdir(partition_folder))]\n",
    "\n",
    "    # Création du DataFrame\n",
    "    df = spark.createDataFrame(data, schema).repartition(10)\n",
    "\n",
    "    # Enregistrer la fonction UDF\n",
    "    schema_components = StructType([\n",
    "        StructField(\"seqID\", StringType(), nullable=False),\n",
    "        StructField(\"component_id\", IntegerType(), nullable=False)\n",
    "    ])\n",
    "\n",
    "    components_udf = F.udf(components, ArrayType(schema_components))\n",
    "\n",
    "    #df_with_components = df.withColumn(\"components\", components_udf(F.concat(F.lit(partition_folder+\"/\"), df[\"file\"])))\n",
    "    df_with_components = df.withColumn(\n",
    "        \"components\",\n",
    "        components_udf(\n",
    "            F.concat(\n",
    "                F.lit(partition_folder + \"/partition_\"), \n",
    "                df[\"file\"] , \n",
    "                F.lit(\".parquet\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return df_with_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3014c20-357a-4c8b-9236-0249c352aa90",
   "metadata": {},
   "source": [
    "# Calcul des composantes connexes du graph complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f7c518-2a67-4236-ad48-7403213f4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def components_2(edges):\n",
    "    # Créer un graphe à partir des arêtes\n",
    "    g = Graph.TupleList(edges, directed=False)\n",
    "    \n",
    "    connected_components = g.connected_components()\n",
    "    node_ids=[]\n",
    "    for component in connected_components:\n",
    "        node_ids.append([g.vs[node_index]['name'] for node_index in component])\n",
    "    #on trie en fonction de la taille \n",
    "    composantes_triees = sorted(node_ids, key=len, reverse=True)\n",
    "    # Créer une liste de lignes pour chaque composante\n",
    "    rows = []\n",
    "    for i, component in enumerate(composantes_triees):\n",
    "        for seqid in component:\n",
    "            rows.append(Row(partial_component=seqid ,component=i ))\n",
    "    \n",
    "    # Créer un DataFrame Spark à partir de la liste de lignes\n",
    "    result_df = spark.createDataFrame(rows)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2bd62aa-2aee-4cdd-875c-5ef7f2d5e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_components(folder_partition ):\n",
    "    # Claclul des composantes partielles dans chaque partition\n",
    "    df_with_components = calculate_partition_components(folder_partition)\n",
    "    df_exploded = df_with_components.select('file',  explode('components').alias('component'))\n",
    "    df_split = df_exploded.select(\"file\", col(\"component.seqID\").alias(\"seqID\"), col(\"component.component_id\").alias(\"component_id\"))\n",
    "    \n",
    "    # Ajouter une colonne d'identifiant unique basée sur le couple (file, component_id)\n",
    "    windowSpec = Window.orderBy(\"file\", \"component_id\")\n",
    "    df = df_split.withColumn(\"new_component_id\", dense_rank().over(windowSpec))\n",
    "    new_df = df.select(\"seqID\",\"new_component_id\")\n",
    "\n",
    "    # new_df = df_split.select(\n",
    "    #             'seqID',\n",
    "    #             concat(col('file'), lit(':'), col('component_id')).alias('new_component_id')\n",
    "    #         )\n",
    "    \n",
    "    #cration d'un graph ou chaque noeud est le numero d'une composante (new_graph)\n",
    "\n",
    "    components_per_node = new_df \\\n",
    "        .groupby(\"seqID\") \\\n",
    "        .agg(collect_set(\"new_component_id\").alias(\"components\")) \\\n",
    "        .withColumn(\"min_component\", array_min(\"components\"))\n",
    "\n",
    "    # components_per_node = new_df \\\n",
    "    #     .groupby(\"seqID\") \\\n",
    "    #     .agg(collect_set(\"new_component_id\").alias(\"components\")) \\\n",
    "    #     .withColumn(\"min_component\", array_min(\"components\"))\n",
    "\n",
    "\n",
    "    components_per_node_exploded = components_per_node.select('seqID', 'min_component', explode('components').alias('component'))\n",
    "    result = components_per_node_exploded.where(col(\"component\") > col(\"min_component\")).drop(\"seqID\").dropDuplicates()\n",
    "  \n",
    "    \n",
    "    new_graph = result.withColumnRenamed(\"min_component\", \"src\").withColumnRenamed(\"component\", \"dst\")\n",
    "\n",
    "    #calcul des composantes sur le nouveau graph\n",
    "    edges =new_graph.select('src', 'dst').collect()\n",
    "    composantes_df = components_2(edges)\n",
    "\n",
    "    composantes_df_exploded = composantes_df \\\n",
    "            .groupby(\"component\") \\\n",
    "            .agg(collect_set(\"partial_component\").alias(\"partial_components\")) \\\n",
    "            .withColumn(\"min_partial_component\", array_min(\"partial_components\")) \\\n",
    "            .selectExpr(\"explode(partial_components) as partial_component\" , \"min_partial_component\")\n",
    "    \n",
    "    #resultat final en faisant une jointure gauche\n",
    "    result = components_per_node.join(composantes_df_exploded, components_per_node.min_component == composantes_df_exploded.partial_component, \"left_outer\") \\\n",
    "               .select(components_per_node.seqID, when(composantes_df_exploded.partial_component.isNull(), components_per_node.min_component).otherwise(composantes_df_exploded.min_partial_component).alias(\"new_component_id\"))\n",
    "\n",
    "\n",
    "    #ecriture du résultat dans des fichier parquet\n",
    "    file_path = f\"/data/bd/dataset/proteine/80_80/G99/graph_nodeID_only\"\n",
    "    result.repartition(1).write.mode(\"overwrite\").parquet(file_path)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148df552-ff55-462d-9afd-2eae9fc14c8b",
   "metadata": {},
   "source": [
    "# Calcul des composantes avec la nouvelle méthode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88940b8c-decd-4916-a25b-72f5c35e2e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.                (0 + 9) / 10]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/root/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1217, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/root/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18613/2723104803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_partition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Temps d'execution avec la nouvelle methode : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18613/1885029974.py\u001b[0m in \u001b[0;36mcalculate_components\u001b[0;34m(folder_partition)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#calcul des composantes sur le nouveau graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnew_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dst'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mcomposantes_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponents_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \"\"\"\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                (0 + 10) / 10][Stage 10:>                 (0 + 0) / 1]\r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "folder_partition = \"/data/bd/dataset/proteine/80_80/G99/graph_nodeID_only_partitionned_200/\"\n",
    "\n",
    "start_time = time.time()\n",
    "result_df = calculate_components(folder_partition)\n",
    "end_time = time.time()\n",
    "print(\"Temps d'execution avec la nouvelle methode : \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0c3f9a3-cd00-46fc-9d7d-39a26d28ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = calculate_partition_components(folder_partition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5334c962-d797-4e48-a6ab-ab18a7e5e589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.                 (0 + 1) / 1]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/root/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1217, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/root/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18613/2916651871.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
