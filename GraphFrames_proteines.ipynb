{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOlc0eSi6ksE"
      },
      "source": [
        "# Notebook API Python Spark GraphFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbxn8n5Io_kY"
      },
      "source": [
        "**GraphFrames Quick-Start Guide:**\n",
        "*   https://graphframes.github.io/graphframes/docs/_site/quick-start.html\n",
        "\n",
        "**GraphFrames User Guide:**\n",
        "*   https://graphframes.github.io/graphframes/docs/_site/user-guide.html\n",
        "\n",
        "**GraphFrames Python API**\n",
        "*   https://graphframes.github.io/graphframes/docs/_site/api/python/index.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtf54D-Z64CH"
      },
      "source": [
        "***Install pyspark and findspark:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioEYznLp69Sm"
      },
      "source": [
        "***Install GraphFrames :***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import igraph as ig\n",
        "import os\n",
        "# !find /usr/local -name \"pyspark\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/home/anyes/spark\"\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QHgUCUv7P5v"
      },
      "source": [
        "***Start the spark session:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS12q7oh7ZBg",
        "outputId": "2cf46bbe-84ae-418b-d7dc-87fb51cfe709"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/02/06 14:39:51 WARN Utils: Your hostname, anyes-Latitude-5480 resolves to a loopback address: 127.0.1.1; using 10.51.22.213 instead (on interface wlp2s0)\n",
            "24/02/06 14:39:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ":: loading settings :: url = jar:file:/home/anyes/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ivy Default Cache set to: /home/anyes/.ivy2/cache\n",
            "The jars for the packages stored in: /home/anyes/.ivy2/jars\n",
            "graphframes#graphframes added as a dependency\n",
            ":: resolving dependencies :: org.apache.spark#spark-submit-parent-3edd8e23-02ba-41b4-8c67-a238892c4604;1.0\n",
            "\tconfs: [default]\n",
            "\tfound graphframes#graphframes;0.8.3-spark3.5-s_2.12 in spark-packages\n",
            "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
            ":: resolution report :: resolve 597ms :: artifacts dl 13ms\n",
            "\t:: modules in use:\n",
            "\tgraphframes#graphframes;0.8.3-spark3.5-s_2.12 from spark-packages in [default]\n",
            "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
            "\t---------------------------------------------------------------------\n",
            "\t|                  |            modules            ||   artifacts   |\n",
            "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
            "\t---------------------------------------------------------------------\n",
            "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
            "\t---------------------------------------------------------------------\n",
            ":: retrieving :: org.apache.spark#spark-submit-parent-3edd8e23-02ba-41b4-8c67-a238892c4604\n",
            "\tconfs: [default]\n",
            "\t0 artifacts copied, 2 already retrieved (0kB/12ms)\n",
            "24/02/06 14:39:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "session started, its id is  local-1707226798546\n"
          ]
        }
      ],
      "source": [
        "# Main imports\n",
        "import findspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkConf\n",
        "\n",
        "# for dataframe and udf\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from datetime import *\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# initialise environment variables for spark\n",
        "findspark.init()\n",
        "\n",
        "# Start spark session\n",
        "# --------------------------\n",
        "def start_spark():\n",
        "  local = \"local[*]\"\n",
        "  appName = \"PLDAC\"\n",
        "\n",
        "  gf = \"graphframes:graphframes:0.8.3-spark3.5-s_2.12\"\n",
        "\n",
        "  configLocale = SparkConf().setAppName(appName).setMaster(local).\\\n",
        "  set(\"spark.executor.memory\", \"6G\").\\\n",
        "  set(\"spark.driver.memory\",\"6G\").\\\n",
        "  set(\"spark.sql.catalogImplementation\",\"in-memory\").\\\n",
        "  set(\"spark.jars.packages\", gf)\n",
        "\n",
        "  spark = SparkSession.builder.config(conf = configLocale).getOrCreate()\n",
        "  sc = spark.sparkContext\n",
        "  sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "  spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\",\"-1\")\n",
        "\n",
        "  # Adjust the query execution environment to the size of the cluster (4 cores)\n",
        "  spark.conf.set(\"spark.sql.shuffle.partitions\",\"4\")\n",
        "  print(\"session started, its id is \", sc.applicationId)\n",
        "  return spark\n",
        "spark = start_spark()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7pVjl4xgTyo",
        "outputId": "6e64f4b0-c92d-420b-abbd-99d67da6e2d2"
      },
      "outputs": [],
      "source": [
        "#Import GraphFrames\n",
        "from graphframes import GraphFrame\n",
        "from graphframes.lib import AggregateMessages as AM\n",
        "from graphframes.lib import Pregel\n",
        "\n",
        "#For connectedComponents()\n",
        "# !pwd\n",
        "# !mkdir /content/checkpoints\n",
        "spark.sparkContext.setCheckpointDir('./content/checkpoints')\n",
        "\n",
        "#Import networkx\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lecture des fichiers du dossier BDLE_10K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJc4RwVTeRE2",
        "outputId": "dcfe1c6f-c09b-4b1e-86e0-b341b2276bd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----------+-----+\n",
            "|     seqID1|     seqID2|  sim|\n",
            "+-----------+-----------+-----+\n",
            "|117761605:5|152890023:5| 97.8|\n",
            "|152904885:3|155591878:2| 88.5|\n",
            "|152887848:4|153682181:0|100.0|\n",
            "|152937692:5| 80009514:2| 82.3|\n",
            "|152990923:2|154549183:4| 98.0|\n",
            "|152867782:1|153171917:1| 83.1|\n",
            "| 15111981:2|153137370:1|100.0|\n",
            "|152794195:0| 15280704:2| 96.9|\n",
            "| 62963742:1| 63783418:5| 98.4|\n",
            "|152170568:3|153062631:2| 97.6|\n",
            "+-----------+-----------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialisez une session Spark\n",
        "spark = SparkSession.builder.appName(\"Proteines_graph\").getOrCreate()\n",
        "\n",
        "parquet_folder = \"./local/data/BDLE_10K\"\n",
        "\n",
        "# Récuperer tous les fichiers Parquet compressé avec Snappy\n",
        "parquet_files = parquet_folder + \"/*.snappy.parquet\"\n",
        "\n",
        "#Création du data frame\n",
        "df = spark.read.format(\"parquet\").option(\"compression\", \"snappy\").load(parquet_files)\n",
        "\n",
        "# Affichez les 10 premiére ligne du DataFrame\n",
        "df.show(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de lignes : 20842\n",
            "Nombre de colonnes : 3\n",
            "Noms des colonnes : ['seqID1', 'seqID2', 'sim']\n"
          ]
        }
      ],
      "source": [
        "# Nombre de lignes\n",
        "nb_rows = df.count()\n",
        "\n",
        "# Liste des noms des colonnes\n",
        "columns_list = df.columns\n",
        "\n",
        "# Nombre de colonnes\n",
        "nb_columns = len(columns_list)\n",
        "\n",
        "# Affichage des informations\n",
        "print(f\"Nombre de lignes : {nb_rows}\")\n",
        "print(f\"Nombre de colonnes : {nb_columns}\")\n",
        "print(f\"Noms des colonnes : {columns_list}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Création d'un graphe avec Graphframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|         id|\n",
            "+-----------+\n",
            "|152904885:3|\n",
            "|152887848:4|\n",
            "|152937692:5|\n",
            "|152990923:2|\n",
            "|152794195:0|\n",
            "|152904832:4|\n",
            "|152745429:3|\n",
            "|153161980:3|\n",
            "|152903373:4|\n",
            "|153040013:0|\n",
            "+-----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+-----------+-----------+-----+\n",
            "|        src|        dst|  sim|\n",
            "+-----------+-----------+-----+\n",
            "|117761605:5|152890023:5| 97.8|\n",
            "|152904885:3|155591878:2| 88.5|\n",
            "|152887848:4|153682181:0|100.0|\n",
            "|152937692:5| 80009514:2| 82.3|\n",
            "|152990923:2|154549183:4| 98.0|\n",
            "|152867782:1|153171917:1| 83.1|\n",
            "| 15111981:2|153137370:1|100.0|\n",
            "|152794195:0| 15280704:2| 96.9|\n",
            "| 62963742:1| 63783418:5| 98.4|\n",
            "|152170568:3|153062631:2| 97.6|\n",
            "+-----------+-----------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Créez un DataFrame distinct contenant tous les identifiants uniques de sommets\n",
        "vertices = df.selectExpr(\"seqID1 as id\").union(df.selectExpr(\"seqID2 as id\")).distinct()\n",
        "\n",
        "# Créez un DataFrame d'arêtes avec les colonnes \"src\", \"dst\", et \"sim\"\n",
        "edges = df.select(\"seqID1\", \"seqID2\", \"sim\").withColumnRenamed(\"seqID1\", \"src\").withColumnRenamed(\"seqID2\", \"dst\")\n",
        "\n",
        "vertices.show(10)\n",
        "\n",
        "edges.show(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de noeuds : 18500\n",
            "Nombre d'arêtes : 20842\n"
          ]
        }
      ],
      "source": [
        "# Créez le GraphFrame\n",
        "graph = GraphFrame(vertices, edges)\n",
        "nombre_noeuds = graph.vertices.count()\n",
        "nombre_aretes = graph.edges.count()\n",
        "\n",
        "print(\"Nombre de noeuds :\", nombre_noeuds)\n",
        "print(\"Nombre d'arêtes :\", nombre_aretes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prendre que les arêtes qui ont un pourcentage de similarité supérieure ou égale à 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de noeuds : 5908\n",
            "Nombre d'arêtes : 4054\n"
          ]
        }
      ],
      "source": [
        "graph_100_edges = graph.edges.filter(\"sim >= 100\")\n",
        "graph_100 = GraphFrame(vertices, graph_100_edges)\n",
        "graph_100 = graph_100.dropIsolatedVertices()\n",
        "\n",
        "nombre_noeuds = graph_100.vertices.count()\n",
        "nombre_aretes = graph_100.edges.count()\n",
        "\n",
        "print(\"Nombre de noeuds :\", nombre_noeuds)\n",
        "print(\"Nombre d'arêtes :\", nombre_aretes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calcul des composantes connexes et le temps d'execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Graph 10k filtré"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rntpXKP4LPe",
        "outputId": "30dea47e-ad3c-4ab1-c172-0d8e319cdeb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temps d'execution :  27.308711290359497\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "connected_components = graph_100.connectedComponents()\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Temps d'execution : \", end_time - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Graph 10K complet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temps d'execution du graphe 10K (Complet):  36.69870591163635\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "connected_components_graph_1K = graph.connectedComponents()\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Temps d'execution du graphe 10K (Complet): \", end_time - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lecture des fichiers du dossier BDLE_1M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----------+-----+\n",
            "|     seqID1|     seqID2|  sim|\n",
            "+-----------+-----------+-----+\n",
            "| 28266027:2| 30697475:4|100.0|\n",
            "|141099253:1|142374057:2| 87.8|\n",
            "|100479579:0| 23509310:0| 83.9|\n",
            "|113579361:3|114583521:5|100.0|\n",
            "|127898390:3|142186630:2|100.0|\n",
            "| 19430332:0| 78781103:4| 85.4|\n",
            "|141834541:2|145255331:5|100.0|\n",
            "|103259805:4| 58392840:4| 83.3|\n",
            "|122611397:5|143667719:3|100.0|\n",
            "| 23535857:4|  4695744:1| 95.8|\n",
            "+-----------+-----------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialisez une session Spark\n",
        "spark = SparkSession.builder.appName(\"Proteines_graph\").getOrCreate()\n",
        "\n",
        "parquet_folder = \"./local/data/BDLE_1M\"\n",
        "\n",
        "# Récuperer tous les fichiers Parquet compressé avec Snappy\n",
        "parquet_files = parquet_folder + \"/*.snappy.parquet\"\n",
        "\n",
        "#Création du data frame\n",
        "df = spark.read.format(\"parquet\").option(\"compression\", \"snappy\").load(parquet_files)\n",
        "\n",
        "# Affichez les 10 premiére ligne du DataFrame\n",
        "df.show(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de lignes : 1768595\n",
            "Nombre de colonnes : 3\n",
            "Noms des colonnes : ['seqID1', 'seqID2', 'sim']\n"
          ]
        }
      ],
      "source": [
        "# Nombre de lignes\n",
        "nb_rows = df.count()\n",
        "\n",
        "# Liste des noms des colonnes\n",
        "columns_list = df.columns\n",
        "\n",
        "# Nombre de colonnes\n",
        "nb_columns = len(columns_list)\n",
        "\n",
        "# Affichage des informations\n",
        "print(f\"Nombre de lignes : {nb_rows}\")\n",
        "print(f\"Nombre de colonnes : {nb_columns}\")\n",
        "print(f\"Noms des colonnes : {columns_list}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Création d'un graphe avec Graphframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Créez un DataFrame distinct contenant tous les identifiants uniques de sommets\n",
        "vertices = df.selectExpr(\"seqID1 as id\").union(df.selectExpr(\"seqID2 as id\")).distinct()\n",
        "\n",
        "# Créez un DataFrame d'arêtes avec les colonnes \"src\", \"dst\", et \"sim\"\n",
        "edges = df.select(\"seqID1\", \"seqID2\", \"sim\").withColumnRenamed(\"seqID1\", \"src\").withColumnRenamed(\"seqID2\", \"dst\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de noeuds : 1505821\n",
            "Nombre d'arêtes : 1768595\n"
          ]
        }
      ],
      "source": [
        "# Créez le GraphFrame\n",
        "graph_1M = GraphFrame(vertices, edges)\n",
        "nombre_noeuds = graph_1M.vertices.count()\n",
        "nombre_aretes = graph_1M.edges.count()\n",
        "\n",
        "print(\"Nombre de noeuds :\", nombre_noeuds)\n",
        "print(\"Nombre d'arêtes :\", nombre_aretes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prendre que les arêtes qui ont un pourcentage de similarité supérieure ou égale à 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de noeuds : 529664\n",
            "Nombre d'arêtes : 375095\n"
          ]
        }
      ],
      "source": [
        "graph_1M_100_edges = graph_1M.edges.filter(\"sim >= 100\")\n",
        "graph_1M_100 = GraphFrame(vertices, graph_1M_100_edges)\n",
        "graph_1M_100 = graph_1M_100.dropIsolatedVertices()\n",
        "\n",
        "nombre_noeuds = graph_1M_100.vertices.count()\n",
        "nombre_aretes = graph_1M_100.edges.count()\n",
        "\n",
        "print(\"Nombre de noeuds :\", nombre_noeuds)\n",
        "print(\"Nombre d'arêtes :\", nombre_aretes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calcul des composantes connexes et le temps d'execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Graph 1M filtré"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 1929:>                                                       (0 + 2) / 2]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temps d'execution :  107.84025692939758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "connected_components = graph_1M_100.connectedComponents()\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Temps d'execution : \", end_time - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Graph 1M complet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 2695:==========================================>             (3 + 1) / 4]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temps d'execution du graphe 10K (Complet):  219.8739836215973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "connected_components = graph_1M.connectedComponents()\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Temps d'execution du graphe 10K (Complet): \", end_time - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le temps d'execution de p1 est  20.8945255279541 secondes\n",
            "Le temps d'execution de p2 est  42.22213077545166 secondes\n",
            "Les deux processus sont terminés\n",
            "Temps d'exécution total (pour les 2 processus): 42.22197937965393 secondes\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "\n",
        "def processus(graph_100):\n",
        "    graph_100.connectedComponents()\n",
        "\n",
        "# Créer les deux processus\n",
        "p1 = multiprocessing.Process(target=processus, args=(graph_100,))\n",
        "p2 = multiprocessing.Process(target=processus, args=(graph_100,))\n",
        "\n",
        "start_time = time.time()  # Enregistrer le temps de début\n",
        "\n",
        "# Démarrer les processus\n",
        "p1.start()\n",
        "p2.start()\n",
        "\n",
        "# Attendre que les processus se terminent\n",
        "p1.join()\n",
        "print(\"Le temps d'execution de p1 est \", time.time() - start_time , \"secondes\")\n",
        "\n",
        "p2.join()\n",
        "end_time = time.time()  # Enregistrer le temps de fin\n",
        "execution_time = end_time - start_time  # Calculer le temps d'exécution\n",
        "print(\"Le temps d'execution de p2 est \", time.time() - start_time , \"secondes\")\n",
        "\n",
        "\n",
        "print(\"Les deux processus sont terminés\")\n",
        "print(\"Temps d'exécution total (pour les 2 processus):\", execution_time, \"secondes\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
