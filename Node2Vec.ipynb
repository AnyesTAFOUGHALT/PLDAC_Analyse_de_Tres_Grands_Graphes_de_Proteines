{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des bibliothéques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import string\n",
    "from node2vec import Node2Vec\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = None #Création d'un graph avec networkx\n",
    "\n",
    "# Générer les embeddings de noeuds avec Node2Vec\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Obtenir les embeddings de noeuds appris\n",
    "node_embeddings = model.wv\n",
    "\n",
    "labeled_nodes = None # La liste des noeuds qui ont des labels\n",
    "one_hot_labels = None # Convertir les étiquettes en vecteurs One-Hot Encoding\n",
    "total_label_count = None # Nombre total de labels (pfam)\n",
    "\n",
    "# Créer les caractéristiques X et les étiquettes y pour la classification\n",
    "X = np.array([node_embeddings.get_vector(str(node)) for node in labeled_nodes])\n",
    "y = np.array([one_hot_labels.get(node, [0] * total_label_count) for node in labeled_nodes])\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Création du classificateur MLPClassifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=100, activation='relu', solver='adam', random_state=42)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les étiquettes pour les données de test\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculer l'exactitude\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définition des hyperparamètres à rechercher\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "# Création de l'objet GridSearchCV\n",
    "grid_search = GridSearchCV(MLPClassifier(random_state=42), param_grid, cv=5)\n",
    "\n",
    "# Recherche des meilleurs hyperparamètres\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs hyperparamètres trouvés\n",
    "print(\"Meilleurs hyperparamètres trouvés :\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Obtention du meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Prédire les étiquettes pour les données de test avec le meilleur modèle\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculer l'exactitude avec le meilleur modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy avec le meilleur modèle:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
